{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all the libraies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import Huber\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOADING THE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"TASK-ML-INTERN.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Dataset info\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "display(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"Missing Values:\\n\", missing_values[missing_values > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values (Only for numeric columns)\n",
    "df.fillna(df.select_dtypes(include=[np.number]).median(), inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize spectral data (excluding target variable)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "spectral_columns = [col for col in df.columns if col not in ['vomitoxin_ppb', 'hsi_id']]\n",
    "scaler = MinMaxScaler()\n",
    "df[spectral_columns] = scaler.fit_transform(df[spectral_columns])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing spectral distributions\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=df[spectral_columns])\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Distribution of Normalized Spectral Features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DIMENTIONALITY REDUCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying PCA for dimentionaliy reduction\n",
    "pca = PCA(n_components=50)  # Reduce to 2D for visualization\n",
    "pca_result = pca.fit_transform(df[spectral_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explained variance\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "print(f\"Explained Variance by Components: {explained_variance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot of PCA components\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(pca_result[:, 0], pca_result[:, 1], c=df['vomitoxin_ppb'], cmap='viridis', alpha=0.7)\n",
    "plt.colorbar(label='Vomitoxin (ppb)')\n",
    "plt.xlabel(\"Principal Component 1\")\n",
    "plt.ylabel(\"Principal Component 2\")\n",
    "plt.title(\"PCA Visualization of Spectral Data\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "\n",
    "X = df[spectral_columns].values.reshape(-1, len(spectral_columns), 1)  # Reshape for CNN input\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "y_scaler = MinMaxScaler()\n",
    "y = y_scaler.fit_transform(df[['vomitoxin_ppb']])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build an optimized CNN model\n",
    "model = Sequential([\n",
    "    Conv1D(filters=128, kernel_size=5, activation='relu', input_shape=(X_train.shape[1], 1)),\n",
    "    BatchNormalization(),\n",
    "    Conv1D(filters=64, kernel_size=3, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Conv1D(filters=32, kernel_size=3, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='linear')  # Regression output\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss=Huber(), metrics=['mae'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=16, validation_data=(X_test, y_test), verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL EALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test).flatten()\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "r2 = r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "print(f\"R¬≤ Score: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot of actual vs. predicted values\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.7, color='blue')\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], '--', color='red')  # Ideal fit line\n",
    "plt.xlabel(\"Actual Vomitoxin (ppb)\")\n",
    "plt.ylabel(\"Predicted Vomitoxin (ppb)\")\n",
    "plt.title(\"Actual vs. Predicted Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Model Performance Summary\n",
    "\n",
    "### ‚úÖ **Performance Metrics**\n",
    "- **Mean Absolute Error (MAE):** 0.0338\n",
    "- **Root Mean Squared Error (RMSE):** 0.0798\n",
    "- **R¬≤ Score:** 0.6092\n",
    "\n",
    "The model shows **moderate predictive accuracy**, with an **R¬≤ score of 0.6092**, meaning it explains about **60.9% of the variance** in the data. The **MAE and RMSE values are relatively low**, indicating that the predictions are not too far from actual values.\n",
    "\n",
    "### ‚ö†Ô∏è **Limitations & Future Improvements**\n",
    "1. **Data Dimensionality:** PCA reduced feature dimensions, which might have caused some **loss of information**.  \n",
    "2. **Model Complexity:** The CNN model might benefit from **further hyperparameter tuning** or **a hybrid approach (CNN + LSTM)**.  \n",
    "3. **Dataset Size:** More data samples could improve model generalization.  \n",
    "4. **Alternative Models:** Exploring **transformer-based models** (e.g., Attention Networks) might improve performance.  \n",
    "\n",
    "### üöÄ **Future Enhancements**\n",
    "- **Hyperparameter tuning** (Grid Search for best filters, kernel sizes).  \n",
    "- **Alternative architectures** (LSTM, Transformer models).  \n",
    "- **Data augmentation** to enhance the dataset for better learning.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
